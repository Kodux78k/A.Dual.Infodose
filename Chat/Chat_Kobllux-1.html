<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="utf-8" />
  <meta content="width=device-width, initial-scale=1" name="viewport" />
  <title>dual.Infodose Chat Cinematogr√°fico</title>
  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&display=swap" rel="stylesheet" />
  <style>
    :root {
      --background-dark: linear-gradient(to bottom, #000000, #1a1a1a);
      --text-dark: white;
      --primary-color: #111111;
      --secondary-color: #5e5c5e;
    }

    body {
      background: var(--background-dark);
      font-family: 'Montserrat', sans-serif;
      color: var(--text-dark);
      margin: 0;
      padding: 0;
      overflow: hidden;
    }

    #camera {
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: -1;
      box-shadow: 0 0 40px rgba(0, 255, 224, 0.03), inset 0 0 40px rgba(0, 255, 224, 0.03);
    }

    .dialog-container {
      position: fixed;
      bottom: 160px;
      width: 90%;
      left: 50%;
      transform: translateX(-50%);
      max-height: 40vh;
      overflow-y: auto;
      background-color: rgba(0, 0, 0, 0.6);
      border-radius: 10px;
      padding: 15px;
      color: white;
      font-size: 16px;
      backdrop-filter: blur(8px);
      z-index: 2;
    }

    .analyze-btn {
      position: fixed;
      bottom: 90px;
      left: 50%;
      transform: translateX(-50%);
      background: none;
      border: none;
      cursor: pointer;
      z-index: 3;
    }

    .analyze-btn img {
      width: 60px;
      height: 60px;
    }

    .switch-camera-btn {
      position: fixed;
      top: 20px;
      right: 20px;
      background: rgba(255, 255, 255, 0.1);
      border: 2px solid white;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      cursor: pointer;
      z-index: 4;
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .switch-camera-btn::before {
      content: '';
      width: 20px;
      height: 20px;
      border: 2px solid white;
      border-radius: 50%;
    }

    .chat-line {
      margin-bottom: 8px;
    }

    .chat-line.user {
      color: #66d9ef;
    }

    .chat-line.ai {
      color: #f5f5f5;
    }
  </style>
</head>
<body>

  <video id="camera" autoplay playsinline muted></video>

  <div class="dialog-container" id="dialogo">
    <div class="chat-line ai">Assistente aguardando an√°lise...</div>
  </div>

  <button class="analyze-btn" onclick="chamarIA()">
    <img src="https://raw.githubusercontent.com/Kodux78k/A.Dual.Infodose/main/Gold_Dual_Infodose.png" alt="Analisar" />
  </button>

  <button class="switch-camera-btn" onclick="alternarCamera()"></button>

  <script type="module">
    import { FaceMesh } from 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js';
    import { Hands } from 'https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js';
    import { Camera } from 'https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js';

    const dialogo = document.getElementById("dialogo");
    const videoElement = document.getElementById('camera');
    let cameraInstance;
    let usandoCameraFrontal = false;

    async function chamarIA() {
      adicionarMensagem("Analisando cena visual...", "user");

      // Exemplo: capturar contexto visual + carregar JSON
      const combinacoes = await carregarCombinacoes();
      const contextoSimulado = "tr√≠ade simb√≥lica detectada: ‚ö°Ô∏è‚ö´Ô∏èüåÄ";

      const prompt = `Baseado nas combina√ß√µes simb√≥licas: ${contextoSimulado}. Responda como IA cinematogr√°fica.`;
      const resposta = await chamarOpenRouter(prompt);

      adicionarMensagem(resposta, "ai");
    }

    function adicionarMensagem(texto, classe) {
      const linha = document.createElement("div");
      linha.className = "chat-line " + classe;
      linha.textContent = texto;
      dialogo.appendChild(linha);
      dialogo.scrollTop = dialogo.scrollHeight;
    }

    async function carregarCombinacoes() {
      try {
        const res = await fetch("https://raw.githubusercontent.com/Kodux78k/A.Dual.Infodose/main/metapulso_70_combinacoes.json");
        if (!res.ok) throw new Error("Erro ao buscar JSON.");
        return await res.json();
      } catch (e) {
        console.error(e);
        return [];
      }
    }

    async function chamarOpenRouter(prompt) {
      const apiKey = "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"; // Substitua pela sua chave
      const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${apiKey}`
        },
        body: JSON.stringify({
          model: "qwen/qwen2.5-vl-3b-instruct:free",
          messages: [{ role: "user", content: prompt }]
        })
      });
      const data = await response.json();
      return data.choices?.[0]?.message?.content || "Erro ao gerar resposta.";
    }

    function alternarCamera() {
      usandoCameraFrontal = !usandoCameraFrontal;
      iniciarCamera();
    }

    async function iniciarCamera() {
      if (cameraInstance) {
        cameraInstance.stop();
      }

      const constraints = {
        video: {
          facingMode: usandoCameraFrontal ? "user" : "environment"
        }
      };

      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        videoElement.srcObject = stream;

        // Inicializar MediaPipe FaceMesh
        const faceMesh = new FaceMesh({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
          }
        });
        faceMesh.setOptions({
          maxNumFaces: 1,
          refineLandmarks: true,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        });
        faceMesh.onResults(onResults);

        // Inicializar MediaPipe Hands
        const hands = new Hands({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
          }
        });
        hands.setOptions({
          maxNumHands: 2,
          modelComplexity: 1,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        });
        hands.onResults(onResults);

        cameraInstance = new Camera(videoElement, {
          onFrame: async () => {
            await faceMesh.send({ image: videoElement });
            await hands.send({ image: videoElement });
          },
          width: 1280,
          height: 720
        });
        cameraInstance.start();
      } catch (e) {
        console.error("Erro ao acessar a c√¢mera:", e);
      }
    }

    function onResults(results) {
      // Aqui voc√™ pode processar os resultados de faceMesh e hands
      // Por exemplo, detectar express√µes faciais ou gestos com as m√£os
      // E gerar prompts mais espec√≠ficos para a IA
    }

    iniciarCamera();
  </script>
</body>
</html>
